{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vignesh312000/Deep_Learning-_CNN/blob/main/Rediminds_prompt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVw6UOV2UM_1",
        "outputId": "d252a3f4-956f-40fc-c9a2-6840cada14cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.25.2)\n"
          ]
        }
      ],
      "source": [
        "pip install opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bg8xJZ1IUZ3X"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jOegwjAEwMYJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQN_dvL7wRAO",
        "outputId": "44660768-8bb7-4bd7-c199-ee751e4902a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M3TT81pMEDFL"
      },
      "outputs": [],
      "source": [
        "# Define parameters\n",
        "num_samples_per_class = 200  # Number of videos per class\n",
        "num_frames = 10  # Number of frames per video\n",
        "image_width, image_height = 224, 224  # Image dimensions\n",
        "num_classes = 2  # Number of classes (violence and non-violence)\n",
        "BATCH_SIZE = 8  # Reduce batch size\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6-2GFuYwahk"
      },
      "outputs": [],
      "source": [
        "def load_video_data(folder_path, label, num_samples):\n",
        "    video_data = []\n",
        "    labels = []\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.endswith('.mp4'):\n",
        "            cap = cv2.VideoCapture(os.path.join(folder_path, filename))\n",
        "            frames = []\n",
        "            while len(frames) < num_samples:\n",
        "                ret, frame = cap.read()\n",
        "                if not ret:\n",
        "                    break\n",
        "                frame = cv2.resize(frame, (image_width, image_height))\n",
        "                frame = frame.astype(np.float32) / 255.0  # Normalize pixel values to [0, 1]\n",
        "                frames.append(frame)\n",
        "            cap.release()\n",
        "            if len(frames) == num_samples:\n",
        "                video_data.append(frames)\n",
        "                labels.append(label)\n",
        "    return np.array(video_data), np.array(labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n-1BCuFkJjKZ"
      },
      "outputs": [],
      "source": [
        "def preprocess_video(video_file, target_width, target_height):\n",
        "    frames = []\n",
        "    cap = cv2.VideoCapture(video_file)\n",
        "    while len(frames) < num_frames:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        frame = cv2.resize(frame, (target_width, target_height))\n",
        "        frame = frame.astype(np.float32) / 255.0  # Normalize pixel values to [0, 1]\n",
        "        frames.append(frame)\n",
        "    cap.release()\n",
        "    return np.array(frames)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tzP9_vK9JmzK"
      },
      "outputs": [],
      "source": [
        "non_violence_folder = '/content/drive/MyDrive/N_V'\n",
        "violence_folder = '/content/drive/MyDrive/V'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZPXBDpgiJmt_"
      },
      "outputs": [],
      "source": [
        "# Load video data for non-violence videos\n",
        "non_violence_data, non_violence_labels = load_video_data(non_violence_folder, label=0, num_samples=num_frames)\n",
        "\n",
        "# Load video data for violence videos\n",
        "violence_data, violence_labels = load_video_data(violence_folder, label=1, num_samples=num_frames)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HdzrljOsfSzQ"
      },
      "outputs": [],
      "source": [
        "# Concatenate the data from both classes\n",
        "X = np.concatenate([non_violence_data, violence_data], axis=0)\n",
        "y = np.concatenate([non_violence_labels, violence_labels])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_AGfbC_Widr",
        "outputId": "3dd81df7-bff2-4efd-f2f3-b98c89be601e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples in dataset: 400\n"
          ]
        }
      ],
      "source": [
        "print(\"Number of samples in dataset:\", len(X))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "egbStEdRnGOD"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "y_onehot = to_categorical(y, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GH0m1Mfeo5or"
      },
      "outputs": [],
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y_onehot, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y65-5GcvfgWP"
      },
      "outputs": [],
      "source": [
        "# Reshape the data for the model\n",
        "X_train_reshaped = X_train.reshape(-1, num_frames, image_height, image_width, 3)\n",
        "X_val_reshaped = X_val.reshape(-1, num_frames, image_height, image_width, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VeKhv4p1hoOd",
        "outputId": "67127d02-08f7-483b-edca-036aee048ca0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train_reshaped shape: (320, 10, 224, 224, 3)\n",
            "y_train shape: (320, 2)\n",
            "X_train_reshaped dtype: float32\n",
            "y_train dtype: float32\n"
          ]
        }
      ],
      "source": [
        "print(\"X_train_reshaped shape:\", X_train_reshaped.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"X_train_reshaped dtype:\", X_train_reshaped.dtype)\n",
        "print(\"y_train dtype:\", y_train.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRRQrIZffefG"
      },
      "outputs": [],
      "source": [
        "# Define function to generate batches of data\n",
        "def data_generator(X, y, batch_size):\n",
        "    num_samples = len(X)\n",
        "    num_batches = num_samples // batch_size\n",
        "    for i in range(num_batches):\n",
        "        start_idx = i * batch_size\n",
        "        end_idx = (i + 1) * batch_size\n",
        "        yield X[start_idx:end_idx], y[start_idx:end_idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dL6rQhUklKpQ"
      },
      "outputs": [],
      "source": [
        "# Define the TensorFlow Dataset for training\n",
        "train_dataset = tf.data.Dataset.from_generator(\n",
        "    lambda: data_generator(X_train_reshaped, y_train, BATCH_SIZE),\n",
        "    output_signature=(\n",
        "        tf.TensorSpec(shape=(None, num_frames, image_height, image_width, 3), dtype=tf.float32),\n",
        "        tf.TensorSpec(shape=(None, num_classes), dtype=tf.float32)\n",
        "    )\n",
        ").cache().shuffle(buffer_size=10000).prefetch(tf.data.experimental.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "13KLxf-4mpZt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEmTz0SPfcFC",
        "outputId": "055ba46c-9684-4ae4-b95e-b848d169e60b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of input batch: (8, 10, 224, 224, 3)\n",
            "Shape of output batch: (8, 2)\n"
          ]
        }
      ],
      "source": [
        "# Print shapes of input and output tensors of the dataset\n",
        "for x_batch, y_batch in train_dataset.take(1):\n",
        "    print(\"Shape of input batch:\", x_batch.shape)\n",
        "    print(\"Shape of output batch:\", y_batch.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O1ZjxbkjkXJA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DfPaugLf0JiF"
      },
      "outputs": [],
      "source": [
        "#  Define CNN model architecture\n",
        "model = models.Sequential([\n",
        "    # Convolutional layers\n",
        "    layers.Conv3D(32, (3, 3, 3), activation='relu', input_shape=(10, 224, 224, 3)),\n",
        "    layers.MaxPooling3D((1, 2, 2)),  # Reduced downsampling\n",
        "    layers.Conv3D(64, (3, 3, 3), activation='relu'),\n",
        "    layers.MaxPooling3D((1, 2, 2)),\n",
        "    layers.Conv3D(128, (3, 3, 3), activation='relu'),\n",
        "    layers.MaxPooling3D((1, 2, 2)),\n",
        "    layers.Conv3D(128, (3, 3, 3), activation='relu'),\n",
        "    layers.MaxPooling3D((1, 2, 2)),\n",
        "    layers.Flatten(),\n",
        "    # Fully connected layers\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.Dense(num_classes, activation='softmax')  # Adjust num_classes based on your task\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9w12SkDq4kYT"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSOYzmY7Pa-K",
        "outputId": "8fe69023-99fc-4463-8aba-5a333c9b548e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: (8, 10, 224, 224, 3)\n",
            "Output shape: (8, 2)\n"
          ]
        }
      ],
      "source": [
        "for x_batch, y_batch in train_dataset:\n",
        "    print(\"Input shape:\", x_batch.shape)\n",
        "    print(\"Output shape:\", y_batch.shape)\n",
        "    break  # Only print the shape of the first batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUEoaDV0ma_w"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTFwhfkr4kRo",
        "outputId": "869cfa2c-f4d6-45ea-9553-e9dc0addf916"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "40/40 [==============================] - 916s 23s/step - loss: 0.7694 - accuracy: 0.5344\n",
            "Epoch 2/10\n",
            "40/40 [==============================] - 906s 23s/step - loss: 0.5713 - accuracy: 0.6844\n",
            "Epoch 3/10\n",
            "40/40 [==============================] - 907s 23s/step - loss: 0.5293 - accuracy: 0.6719\n",
            "Epoch 4/10\n",
            "40/40 [==============================] - 906s 23s/step - loss: 0.5045 - accuracy: 0.7437\n",
            "Epoch 5/10\n",
            "40/40 [==============================] - 903s 23s/step - loss: 0.4768 - accuracy: 0.7563\n",
            "Epoch 6/10\n",
            "40/40 [==============================] - 894s 22s/step - loss: 0.4484 - accuracy: 0.7937\n",
            "Epoch 7/10\n",
            "40/40 [==============================] - 894s 22s/step - loss: 0.4819 - accuracy: 0.7625\n",
            "Epoch 8/10\n",
            "40/40 [==============================] - 893s 22s/step - loss: 0.5584 - accuracy: 0.7344\n",
            "Epoch 9/10\n",
            "40/40 [==============================] - 892s 22s/step - loss: 0.4658 - accuracy: 0.7500\n",
            "Epoch 10/10\n",
            "40/40 [==============================] - 893s 22s/step - loss: 0.4140 - accuracy: 0.7969\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "history = model.fit(train_dataset, epochs=10)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7V8B4mt4nCn",
        "outputId": "889e8765-0270-46eb-ec2d-7d9ff9a8e7eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40/40 [==============================] - 207s 5s/step - loss: 0.3995 - accuracy: 0.7969\n",
            "Train Loss: 0.39948439598083496, Train Accuracy: 0.796875\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(train_dataset)\n",
        "print(f\"Train Loss: {loss}, Train Accuracy: {accuracy}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOFJjlwDPewqAM3ZQHE9oXq",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}